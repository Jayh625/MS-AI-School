{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeNet-5 실습 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터셋, 데이터로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5), (0.2,0.2,0.2))\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5), (0.2,0.2,0.2))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_data = CIFAR10(root=\"./data\", train=True, download=True, transform=train_transform)\n",
    "test_data = CIFAR10(root=\"./data\", train=False, download=True, transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LeNet-5 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module) :\n",
    "    def __init__(self) :\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3) # 입력 채널, 출력 채널 수, 커널 사이즈\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3) # 입력 채널 : conv1 출력채널수, 출력 채널수: conv1 출력채널수 * pool수, 커널 사이즈\n",
    "        self.fc1 = nn.Linear(64 * 6 * 6, 64) # 크기조정\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x) : \n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # 1차원으로 펼치기\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval(model) : \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    # 학습 loop\n",
    "    for epoch in range(5) :\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader, 0) :\n",
    "            images, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i % 200 == 190 :\n",
    "                print(f\"Epoch [{epoch+1}/{i+1}], loss :{running_loss/200:.3f}\")\n",
    "                running_loss = 0.0\n",
    "    print(\"Finished Training\")\n",
    "\n",
    "    # 모델 평가\n",
    "    correct = 0 \n",
    "    total = 0\n",
    "    with torch.no_grad() :\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    acc = 100 * correct / total\n",
    "    print(f\"Accuracy : {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet-5\n",
      "Epoch [1/191], loss :2.152\n",
      "Epoch [1/391], loss :2.057\n",
      "Epoch [1/591], loss :1.897\n",
      "Epoch [2/191], loss :1.656\n",
      "Epoch [2/391], loss :1.677\n",
      "Epoch [2/591], loss :1.616\n",
      "Epoch [3/191], loss :1.471\n",
      "Epoch [3/391], loss :1.517\n",
      "Epoch [3/591], loss :1.479\n",
      "Epoch [4/191], loss :1.379\n",
      "Epoch [4/391], loss :1.382\n",
      "Epoch [4/591], loss :1.394\n",
      "Epoch [5/191], loss :1.283\n",
      "Epoch [5/391], loss :1.330\n",
      "Epoch [5/591], loss :1.310\n",
      "Finished Training\n",
      "Accuracy : 55.14\n",
      "Lenet 167562\n"
     ]
    }
   ],
   "source": [
    "print(\"LeNet-5\")\n",
    "model = LeNet()\n",
    "train_and_eval(model=model)\n",
    "\n",
    "# 파라미터수\n",
    "print(f\"Lenet {sum(p.numel() for p in model.parameters())}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
